{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12777001,"sourceType":"datasetVersion","datasetId":8077544},{"sourceId":12777015,"sourceType":"datasetVersion","datasetId":8077552}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\nThe hustle and bustle of the city isn't always so seamless. Between 2012 and 2025, over 2,000,000 car accidents and 379,000 injurues occurred across the busy streets of New York City. Maybe were taking bumper to bumper traffic a little too seriously. The goal of this analysis will be to determine where and why these accidents occurred as well as break down influencing factors that led to them. The last 5 complete years of data (2019-2024) were used to assess yearly trends and see where the big apple is headed.","metadata":{}},{"cell_type":"markdown","source":"# Datasets\n\nThe initial accidents dataset was sourced from NYC Open Data and contained 2,167,918 rows of incidents and 29 columns with the associated information that was recorded. However, for the purposes of this analysis, only 18 rows were imported. Columns were broken down into the following:\n\n* The **CRASH DATE** column contains the date of each accident in mm/dd/yyyy format (e.g., 09/11/2021)\n* The **CRASH TIME** column contains the hour and minute each accident occurred represented in military time(e.g.,13:21)\n* The **BOROUGH** column contains the name of the NYC borough the accident occurred in (e.g., MANHATTAN, BROOKLYN, QUEENS)\n* The **NUMBER OF PERSONS INJURED** column contains the number of people injured in each accident e.g., 4)\n* The **NUMBER OF PERSONS KILLED** column contains the number of people killed in each accident e.g., 4)\n* The **NUMBER OF PEDESTRIANS INJURED** column contains the number of pedestrians injured in each accident (e.g., 3)\n* The **NUMBER OF PEDESTRIANS KILLED** column contains the number of pedestrians killed in each accident (e.g., 0)\n* The **NUMBER OF CYCLISTS INJURED** column contains the number of pedestrians injured in each accident (e.g., 2)\n* The **NUMBER OF CYCLISTS KILLED** column contains the number of pedestrians killed in each accident (e.g., 1)\n* The **NUMBER OF MOTORISTS INJURED** column contains the number of motorists injured in each accident (e.g., 2)\n* The **NUMBER OF MOTORISTS KILLED** column contains the number of motorists killed in each accident (e.g., 1)\n* The **CONTRIBUTING FACTOR VEHICLE 1** columns contains the recorded the reason the primary vehicle got in an accident (e.g.,. Driver Inexperience)\n* The **CONTRIBUTING FACTOR VEHICLE 2** columns contains the recorded the reason the secondary vehicle got in an accident (Following Too Closely).\n* The **COLLISION_ID** column contains the unique identifier for each accident (e.g., 4455765).\n* The **VEHICLE TYPE CODE 1** column contains the type of the primary vehicle(e.g., Sedan).\n* The **VEHICLE TYPE CODE 2** column contains the type of the secondary vehicle(e.g., Box Truck).\n* The **LATITUDE** column contains the latitude value of each accident.\n* The **LONGITUDE** column contains the longitude value of each accident.\n\nThe Initial traffic volume dataset was also sourced from NYC Open Data and contained over 1,700,000 samples of traffic through various checkpoints like bridges and tunnels all over NYC at various times of the year. Counts were not all encompassing For the purposes of this analysis only 2 out of 14 columns were imported. Columns were broken down into the following:\n\n* The **Yr** column contains the year of each sample (e.g., 2021)\n* The **Vol** column contains the number of cars that passed the checkpoint over a 15 minute period. (e.g., 1150)","metadata":{}},{"cell_type":"markdown","source":"# Necessary Libraries","metadata":{}},{"cell_type":"code","source":"!pip install python-Levenshtein #Installing Levenshtein\n!pip install swifter # Installing swifter\n\nimport swifter #Importing swifter to improve the performance of .apply()\nimport Levenshtein #Importing Levenshtein to improve performance of fuzzywuzzy\nimport pandas as pd #importing pandas\nfrom fuzzywuzzy import fuzz # Importing fuzz to consolidate mispelled words\nimport matplotlib.pyplot as plt # Importing Seaborn to create visualizations\nimport seaborn as sns # Importing pyplot to create visualizations\nimport geopandas as gpd # Importing geopandas to work with geospatial data\nfrom shapely.geometry import Point # importing Point to create geometric point objects\n","metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2026-02-14T22:29:13.135905Z","iopub.execute_input":"2026-02-14T22:29:13.136205Z"}},"outputs":[{"name":"stdout","text":"Collecting python-Levenshtein\n  Downloading python_levenshtein-0.27.3-py3-none-any.whl.metadata (3.9 kB)\nCollecting Levenshtein==0.27.3 (from python-Levenshtein)\n  Downloading levenshtein-0.27.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\nCollecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.3->python-Levenshtein)\n  Downloading rapidfuzz-3.14.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\nDownloading python_levenshtein-0.27.3-py3-none-any.whl (9.5 kB)\nDownloading levenshtein-0.27.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/153.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.14.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"pd.options.display.float_format = '{:,.0f}'.format\npd.options.display.max_columns = None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inspecting the dataframe\n\nAfter its creation, the dataframe's info and number of null values were taken to gain more insight. The borough, contributing_factor_vehicle_2, vehicle_type_code_2, latitude, and longitude columns contained a large number of null values. This may be due to inconsistencies or mistakes in police reports. The vehicle_type_code_1 and contributing_factor_vehicle_1 also contained null values to a lesser extent. Accident data for all of 2025 was not available, as the year is incomplete. ","metadata":{}},{"cell_type":"code","source":"# Creating dataframe with relevant columns\ntraffic_df = pd.read_csv('/kaggle/input/nyc-open-data-accidents/Motor_Vehicle_Collisions_-_Crashes_20250815.csv',usecols = ['NUMBER OF MOTORIST INJURED','NUMBER OF MOTORIST KILLED','NUMBER OF CYCLIST INJURED','NUMBER OF CYCLIST KILLED','NUMBER OF PEDESTRIANS INJURED','NUMBER OF PEDESTRIANS KILLED','CRASH DATE','CRASH TIME','BOROUGH','NUMBER OF PERSONS INJURED','NUMBER OF PERSONS KILLED','CONTRIBUTING FACTOR VEHICLE 1','CONTRIBUTING FACTOR VEHICLE 2','COLLISION_ID','VEHICLE TYPE CODE 1','VEHICLE TYPE CODE 2','LATITUDE','LONGITUDE'])\n\n# Creating list of updated col names\nnew_columns = ['crash_date','crash_time', 'borough','latitude','longitude',\n'number_of_persons_injured','number_of_persons_killed','number_of_pedestrians_injured',\n'number_of_pedestrians_killed','number_of_cyclist_injured','number_of_cyclist_killed',\n'number_of_motorist_injured','number_of_motorist_killed','contributing_factor_vehicle_1',\n'contributing_factor_vehicle_2','collision_id','vehicle_type_code_1','vehicle_type_code_2']\n\n# Assigning column names\ntraffic_df.columns = new_columns ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"traffic_df.isnull().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"traffic_df.info()","metadata":{"trusted":true,"_kg_hide-output":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cleaning the dataframe\n\n9 out of the 18 columns contained null values. Outside of the borough, contributing_factors_vehicle_2, and vehicle_type_code_2 columns, these null values were negligible and represented less than 10 percent of the data frame. Null values outside of the borough column were left as imputation methods would not affect the calculated statistics.\n\nThe Shapely and GeoPandas libraries were used to create a function mapping longitude and latitude pairs to their respective boroughs using a geographic dataframe. This reduced the number of null values in the borough column by 82%. This approach was faster and more accurate than methods using APIs or general borough boundaries. To clean the vehicle type columns a list of correct common vehicle spellings were passed into a separate function to standardize incorrect spellings using the fuzzywuzzy library.\n\n\nThe crash_date and crash_time columns were converted into datetime format to allow for time comparisons and calculations to be run. The number_of_persons_injured and number_of_persons_killed columns were also converted from the object to the float64 data type. The dataframe was then filtered to include the last five complete years of data (2018-2024). This allowed for faster processing and a focus on recent trends. ","metadata":{}},{"cell_type":"code","source":"# Converting data types and filtering years\ntraffic_df['crash_date'] = pd.to_datetime(traffic_df['crash_date'])\ntraffic_df['crash_time'] = pd.to_datetime(traffic_df['crash_time'], format='%H:%M', errors='coerce')\ntraffic_df['number_of_persons_injured'] = pd.to_numeric(traffic_df['number_of_persons_injured'])\ntraffic_df['number_of_persons_killed'] = pd.to_numeric(traffic_df['number_of_persons_killed'])\n\ntraffic_df = traffic_df[(traffic_df['crash_date'].dt.year >= 2018) & (traffic_df['crash_date'].dt.year < 2025)]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculating % of null values\nnull_rows = traffic_df.isnull().sum()\ntotal_rows = len(traffic_df)\nprint((null_rows/total_rows * 100).round(2))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Cleaning The \"borough\" Column","metadata":{}},{"cell_type":"code","source":"# Loading NYC borough boundaries from NYC Open Data\n\nurl = 'https://services5.arcgis.com/GfwWNkhOj9bNBqoJ/arcgis/rest/services/NYC_Borough_Boundary_Water_Included/FeatureServer/0/query?where=1=1&outFields=*&outSR=4326&f=pgeojson'\nboundaries_gdf = gpd.read_file(url)\n    \nprint(f\"Successfully loaded {len(boundaries_gdf)} borough boundaries\")\nprint(\"Borough names:\", boundaries_gdf['BoroName'].tolist())\n\ndef get_borough_from_coordinates_geopandas(traffic_df, boundaries_gdf):\n    \"\"\"Vectorized borough determination using GeoPandas for large datasets\"\"\"\n    # Filtering for rows with missing boroughs and valid coordinates\n    missing_borough_mask = traffic_df['borough'].isna()\n    valid_coords_mask = traffic_df['latitude'].notna() & traffic_df['longitude'].notna()\n    process_mask = missing_borough_mask & valid_coords_mask\n\n\n    # Creating GeoDataFrame from traffic data coordinates, preserving original index\n    subset_df = traffic_df.loc[process_mask].copy()\n    geometry = [Point(lon, lat) for lon, lat in \n                zip(subset_df['longitude'], subset_df['latitude'])]\n\n    points_gdf = gpd.GeoDataFrame(subset_df, geometry=geometry, crs='EPSG:4326')\n\n    # Ensuring both GeoDataFrames use the same CRS\n    if boundaries_gdf.crs != points_gdf.crs:\n        boundaries_gdf = boundaries_gdf.to_crs(points_gdf.crs)\n\n    # Performing spatial join on points_gdf\n    joined = gpd.sjoin(points_gdf, boundaries_gdf, how='left', predicate='within')\n\n    # Updating rows where borough match was found\n    borough_found_mask = joined['BoroName'].notna()\n    if borough_found_mask.any():\n        # Using the index from joined to update the correct rows in the original dataframe\n        indices_to_update = joined.index[borough_found_mask]\n        borough_values = joined.loc[borough_found_mask, 'BoroName'].str.upper()\n        traffic_df.loc[indices_to_update, 'borough'] = borough_values\n\n# Processing coordinates using GeoPandas\nif boundaries_gdf is not None: \n    print(f\"Missing boroughs before: {traffic_df['borough'].isna().sum()}\")\n    \n    get_borough_from_coordinates_geopandas(traffic_df, boundaries_gdf)\n    \n    print(f\"Missing boroughs after: {traffic_df['borough'].isna().sum()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Analyzing why boroughs are still missing\nmissing_borough_mask = traffic_df['borough'].isna()\nmissing_records = traffic_df[missing_borough_mask]\n    \nprint(f\"Total records with missing boroughs: {len(missing_records)}\")\n    \n# Checking for missing coordinates\nmissing_lat = missing_records['latitude'].isna().sum()\nmissing_lon = missing_records['longitude'].isna().sum()\nmissing_both = missing_records[missing_records['latitude'].isna() | missing_records['longitude'].isna()]\n    \nprint(f\"Records with missing coordinates (either lat or lon): {len(missing_both)}\")\n\nprint('Remaining records must contain coordinates outside NYC boundaries')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Cleaning \"vehicle_type_code_1\" and  \"vehicle_type_code_2\" columns","metadata":{}},{"cell_type":"code","source":"# Checking for unique entries\nprint(traffic_df['vehicle_type_code_1'].value_counts())\nprint(traffic_df['vehicle_type_code_2'].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creating list of correct spellings and groupings to check against 'vehicle_type_code_1' column\ncorrected_vehicles = ['Sedan', 'Pick-up Truck','Bike','Ambulance','Motorcycle','Box Truck','FDNY TRUCK','FDNY Ambulance','Ambulance','Fire Truck','Fire Engine','Passenger','Forklift','Flat Bed','School Bus','Sprinter','U-Haul','USPS','Utility','EMS','E-scooter','Station Wagon/Sport Utility Vehicle', 'PASSENGER VEHICLE', 'SPORT UTILITY / STATION WAGON ','Taxi','Bus','Van']\n\ntraffic_df['vehicle_type_code_1'] = traffic_df['vehicle_type_code_1'].astype(str)\ntraffic_df['vehicle_type_code_2'] = traffic_df['vehicle_type_code_2'].astype(str)\n\n\ndef correct_spelling_optimized(text, correct_list, threshold=50):\n    \"\"\"Optimized spelling correction function\"\"\"\n    if pd.isna(text) or text == 'nan':\n        return text\n\n    # Passing over correct spellings\n    if text in correct_list:\n        return text\n\n    # Check for any match above threshold\n    for correct_word in correct_list:\n        if fuzz.ratio(text, correct_word) >= threshold:\n            return correct_word\n\n    # Return original if no match found\n    return text\n\n# Applying corrections\ntraffic_df['vehicle_type_code_1'] = traffic_df['vehicle_type_code_1'].swifter.apply(lambda x: correct_spelling_optimized(x, corrected_vehicles))\ntraffic_df['vehicle_type_code_2'] = traffic_df['vehicle_type_code_2'].swifter.apply(lambda x: correct_spelling_optimized(x, corrected_vehicles))\n\nprint(traffic_df['vehicle_type_code_1'].value_counts())\nprint(traffic_df['vehicle_type_code_2'].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"code","source":"traffic_df.head().T","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Analysis\n###  Traffic volume and Crash Trend\nBetween 2018 and 2024 a steep decline of traffic accidents can be seen, dropping from 231,564 in 2018 to 91,287 in 2024. A sharp decline can be seen between 2019 and 2020, likely due to the start of the COVID-19 pandemic, which resulted in less travel as more people stayed indoors. Rough traffic volume numbers frm NYC Open Data confirm this. However, accidents continued to decline post pandemic into 2023 which can be attributed to the continued efforts of safetly programs. While injuries generally followed accident trends, fatalities did not. During the peak of the pandemic (2020-2021), the number of fatalities reported was markedly higher than the years before or after. This could be due to increased speeding and reckless driving.","metadata":{}},{"cell_type":"code","source":"# Creating dataframe of yearly statistics\ntraffic_df['crash_year'] = traffic_df['crash_date'].dt.year\ntraffic_df['accidents'] = traffic_df['collision_id'].count()\n\n# Creating dataframes of collisions,fatalities, and injuries.\naccidents = traffic_df.groupby('crash_year')['collision_id'].count().reset_index(name = 'accidents')\nfatalities = traffic_df.groupby('crash_year')['number_of_persons_killed'].sum().astype('int')\ninjuries = traffic_df.groupby('crash_year')['number_of_persons_injured'].sum().astype('int')\n\n# Merging dataframes and outputting results\nyearly_breakdown = accidents.merge(fatalities, on='crash_year').merge(injuries, on='crash_year')\nyearly_breakdown = yearly_breakdown[['crash_year', 'accidents', 'number_of_persons_injured', 'number_of_persons_killed']]\n\n\nprint(yearly_breakdown.to_string(index = False,\n    formatters={c: '{:,}'.format for c in yearly_breakdown.select_dtypes('number') if c != 'crash_year'}\n))\n\n\n\n\n# Creating dataframe of sample traffic volume from NYC Open Data\ntraffic_volume = pd.read_csv('/kaggle/input/nyc-open-data-traffic-counts/Automated_Traffic_Volume_Counts_20250814-2.csv')\nyearly_traffic_volume = traffic_volume.groupby('Yr')['Vol'].sum().reset_index(name = 'count')\n\n\n# Creating lineplot of accidents over the years\n\n# YOU NEED TO FIND A PROPER PLACE FOR THIS\nfrom matplotlib.ticker import FuncFormatter\ncomma_fmt = FuncFormatter(lambda x, _: f'{int(x):,}')\n\nfig, ax1 = plt.subplots(figsize=(6,4))\nax1.plot('crash_year','accidents', data = yearly_breakdown)\nax1.set_xlabel('Year')\nax1.set_ylabel('Accident Count',color = 'blue')\nax1.tick_params(axis='y', labelcolor='blue')\nplt.ticklabel_format(style='plain', axis='both')\nax1.yaxis.set_major_formatter(comma_fmt) \n\nax2 = ax1.twinx()  # second y-axis\nax2.plot('Yr','count', color = 'red', data = yearly_traffic_volume)\nax2.set_ylabel('Traffic Volume', color='red')\nax2.tick_params(axis='y', labelcolor='red')\nax2.ticklabel_format(style = 'plain', axis = 'y')\nax2.yaxis.set_major_formatter(comma_fmt)\nplt.show()\nplt.tight_layout()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"yearly_traffic_volume.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Creating objects for the numebr of accidents,injuries, and fatalities\nnumber_of_accidents = traffic_df['collision_id'].count()\nnumber_of_injuries = traffic_df['number_of_persons_injured'].sum()\nnumber_of_fatalities = traffic_df['number_of_persons_killed'].sum()\n\nprint(f\"Number of Accidents: {number_of_accidents}\")\nprint(f\"Number of Persons Injured: {int(number_of_injuries)}\")\nprint(f\"Number of Persons Killed: {int(number_of_fatalities)}\")\nprint(f\"Injury Rate: {(number_of_injuries / number_of_accidents)*100:.2f}%\")\nprint(f\"Fatality Rate: {(number_of_fatalities / number_of_accidents)*100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Hourly Accident Breakdown\nAccidents occur the most between the hours of 9am and 6pm, with their daily peak occurring between 4pm and 6pm. This is followed by a decline into the evening/night, with the fewest accidents occurring between 1am and 5am. However, this trend changes during the weekend when accidents are more evenly spread throughout all hours. The absolute peak and trough occur on Friday from 4pm to 5pm and on Tuesday from 3am to 4am. This pattern is consistent with people commuting to work weekdays and being more active early in the morning and late at night on weekends. Overall Friday and Saturday had the highest number of accidents. It is interesting to note that accidents trend up between 12am to 1am regardless of day.","metadata":{}},{"cell_type":"code","source":"# Creating 'DAY OF WEEK' and 'CRASH HOUR' columns\ntraffic_df['day_of_week'] = traffic_df['crash_date'].dt.day_name()\ntraffic_df['crash_hour'] = traffic_df['crash_time'].dt.hour\n\n# Creating dataframe to group accidents by day of week and index them by crash hour\naccident_counts_day_time = traffic_df.groupby(['crash_hour','day_of_week']).size().reset_index(name='count')\naccident_heatmap_data = accident_counts_day_time.pivot(index= 'crash_hour', columns= 'day_of_week', values='count')\n\n# Reordering 'DAYS OF WEEK'\nday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n\nplt.title('Accidents by Day and Time')\nplt.xlabel('Day of Week')\nplt.ylabel('Hour of Day')\nplt.yticks(rotation=0)\nplt.xticks(rotation=45)\nplt.tight_layout()\n\n# Creating barchart\naccident_heatmap_data = accident_heatmap_data.reindex(columns = day_order)\nax = sns.heatmap(accident_heatmap_data)\n\n# Format the colorbar values with commas\ncolorbar = ax.collections[0].colorbar\ncolorbar.ax.yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{int(x):,}'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(f\"Total Accidents by {accident_heatmap_data.sum()}\")\n\nPeak_Accidents_mask = accident_counts_day_time['count'].max()\nTrough_Accidents_mask = accident_counts_day_time['count'].min()\n\nprint('The Most Accidents Occured On')\nprint('--------------------------------')\nprint(accident_counts_day_time[accident_counts_day_time['count'] == Peak_Accidents_mask]) \nprint('   ')\nprint('The Least Accidents Occured On')\nprint('--------------------------------')\nprint(accident_counts_day_time[accident_counts_day_time['count'] == Trough_Accidents_mask])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Most Frequent Accident Causes\nThe most common cause of accidents at all hours is \"Driver Inattention/Distraction.\" This is followed by \"Following too Closely\" and \"Failure to Yield Right-of-Way\" during most hours of the day. While the majority of accident causes remain consistent throughout all hours, however, \"Unsafe Speed\" saw an increase in the evening through the early morning. This is likely due to the lower volume of cars on the road during those periods.","metadata":{}},{"cell_type":"code","source":"# Creating objects to filter contributing factors\nTop_10_factors = traffic_df['contributing_factor_vehicle_1'].value_counts(ascending = False).head(10).index.tolist()\nTop_10_factors_2 = traffic_df['contributing_factor_vehicle_2'].value_counts(ascending = False).head(10).index.tolist()\n\n# Counting contributing factors by crash hour and contributing factor\naccident_counts_reason_time = traffic_df.groupby(['crash_hour','contributing_factor_vehicle_1']).size().reset_index(name = 'count')\naccident_counts_reason_time_2 = traffic_df.groupby(['crash_hour','contributing_factor_vehicle_2']).size().reset_index(name = 'count')\n\n# Applying filters\naccident_counts_reason_time_filtered = accident_counts_reason_time[accident_counts_reason_time['contributing_factor_vehicle_1'].isin(Top_10_factors) & (accident_counts_reason_time['contributing_factor_vehicle_1'] != 'Unspecified')]\naccident_counts_reason_time_2_filtered = accident_counts_reason_time_2[accident_counts_reason_time_2['contributing_factor_vehicle_2'].isin(Top_10_factors_2) & (accident_counts_reason_time_2['contributing_factor_vehicle_2'] != 'Unspecified')]\n\n# Creating color dictionary and lineplots\nfig,ax = plt.subplots(1,2,figsize=(12,6))\nplt.suptitle('Accidents by reason and time')\nax[0].set_title('Primary Reason'), ax[1].set_title('Secondary Reason')\nax[0].set_xlabel('Hour of Day'),ax[1].set_xlabel('Hour of Day')\n\ncolor_dict = {'Driver Inattention/Distraction':'#ff7f0e','Other Vehicular':'#d62728','Failure to Yield Right-of-Way':'#1f77b4','Following Too Closely':'#2ca02c','Passing Too Closely':'#9467bd','Passing or Lane Usage Improper':'#8c564b','Unsafe Lane Changing':'#7f7f7f','Unsafe Speed':'#bcbd22','Passing Too Closely':'#9467bd','Backing Unsafely':'#17becf','Traffic Control Disregarded':'#e377c2'}\n\nsns.lineplot(data = accident_counts_reason_time_filtered,x = 'crash_hour',y = 'count',hue = 'contributing_factor_vehicle_1',ax=ax[0], palette = color_dict)\nsns.lineplot(data = accident_counts_reason_time_2_filtered,x = 'crash_hour',y = 'count',hue = 'contributing_factor_vehicle_2',ax=ax[1], palette = color_dict,legend = False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Most Accident Prone Vehicles\nThe top 5 most common vehicles involved in accidents are Sedans and SUVs by far, followed by  Taxis, Bikes, and Pick-up Trucks. The prevalence of Sedans and SUVs/Station wagons are likely responsible for their high numbers. The prescence of bikes in the top 5 vehicles in accidents shows the need for not only improved traffic regulations, but also protection for cyclist.","metadata":{}},{"cell_type":"code","source":"# Making chart easier to read\ntraffic_df['vehicle_type_code_1']\ntraffic_df['vehicle_type_code_2']\n\n# Creating objects for vehicle codes\nvehicles_codes_1 = traffic_df['vehicle_type_code_1']\nvehicles_codes_2 = traffic_df['vehicle_type_code_2']\n\n# Concatenating dataframes and removing null values\ncombined_vehicle_codes = pd.concat([vehicles_codes_1, vehicles_codes_2])\nvehicle_totals = combined_vehicle_codes.value_counts().reset_index()\nvehicle_totals.columns = ['vehicle_type','count']\nvehicle_totals_clean = vehicle_totals[vehicle_totals['vehicle_type'] != 'nan']\n\n# Making chart easier to read\nvehicle_totals_clean = vehicle_totals_clean.replace('Station Wagon/Sport Utility Vehicle', 'SUV/Station Wagon')\n\n# Getting top 5 vehicles overall and creating a barchart \ntop_5_vehicles = vehicle_totals_clean.head(5)\nsns.barplot(data = top_5_vehicles, x = 'vehicle_type', y = 'count')\n\n\n\n    \nplt.title(\"Top 5 Vehicle Count by Type\")\nplt.xlabel('Vehicle Type')\nplt.ylabel('Vehicle Count')\nplt.tight_layout()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Borough Statistics\n\nBrooklyn, followed by Queens, had the most accidents over the period. This was followed by Manhattan, the Bronx, and Staten Island, respectively. Total injuries and fatalities followed the same trend. However, while the injury and fatality rates were similar across boroughs, Brooklyn had the highest injury rate, while Staten Island had the highest fatality rate. Out of all the boroughs, Manhattan had the highest non-motorist injury rate, likely due to the high amount of foot and bike traffic compared to the other boroughs.","metadata":{}},{"cell_type":"code","source":"# Creating borough stats dataframe, renaming, and adding columns\nborough_stats = traffic_df.groupby('borough').agg({\n    'collision_id': 'count',  # accidents count\n    'number_of_persons_injured': 'sum',\n    'number_of_persons_killed': 'sum', \n    'number_of_motorist_injured': 'sum',\n    'number_of_motorist_killed': 'sum',\n    'number_of_pedestrians_injured':'sum',\n    'number_of_pedestrians_killed': 'sum',\n    'number_of_cyclist_injured': 'sum',\n    'number_of_cyclist_killed': 'sum'\n    }).reset_index()\n\nborough_stats.columns = ['borough', 'accidents', 'injuries', 'fatalities','motorist_inj','motorist_fat', 'pedestrian_inj','pedestrian_fat','cyclist_inj', 'cyclist_fat']\n\nborough_stats['non_driver_inj'] = (borough_stats['cyclist_inj'] + borough_stats['pedestrian_inj'])\nborough_stats['non_driver_fat'] = (borough_stats['cyclist_fat'] + borough_stats['pedestrian_fat'])\n\n# Calculating rates\npct_rate = ['injury_rate', 'fatality_rate', 'motorist_injury_rate', 'motorist_fat_rate', 'non_driver_inj_rate', 'non_driver_fat_rate']\ntotals = ['injuries', 'fatalities', 'motorist_inj', 'motorist_fat', 'non_driver_inj', 'non_driver_fat']\n\nfor i, col in enumerate(totals):\n    if col in borough_stats.columns and i < len(pct_rate):\n        borough_stats[pct_rate[i]] = (borough_stats[col] / borough_stats['accidents'] * 100).round(2)\n\n# Formatting outputs\ndisplay = borough_stats.copy()\nnumeric_cols = ['injuries','motorist_inj','non_driver_inj', 'fatalities','motorist_fat','non_driver_fat']  # specify your columns\n\nfor col in numeric_cols:\n    if col in display.columns:\n        display[col] = display[col].apply(lambda x: f'{x:,.0f}' if pd.notna(x) else x)\n        \npct_col = ['injury_rate','fatality_rate','motorist_injury_rate','motorist_fat_rate','non_driver_inj_rate','non_driver_fat_rate']\n\nfor col in pct_col:\n        if col in display.columns:\n            display[col] = display[col].apply(lambda x: f'{x:,.2f}%' if pd.notna(x) else x)\n            \n# Reordering output\ncol_order = ['borough', 'accidents', 'injuries','injury_rate','fatalities','fatality_rate','motorist_inj','motorist_injury_rate','motorist_fat','motorist_fat_rate','non_driver_inj','non_driver_inj_rate','non_driver_fat','non_driver_fat_rate']\n\ndisplay[col_order]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creating barchart of % of total accidents\nfig, ax = plt.subplots(figsize=(12, 4))\nplt.suptitle('Accident % by Borough')\nplt.pie(data = borough_stats,x = 'accidents', autopct='%1.1f%%', labels = ['Bronx','Brooklyn','Manhattan','Queens','Staten Island'])\nplt.axis('equal')  # Ensuring pie chart is centered\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax = plt.subplots(3, 2, figsize=(16, 14))\nplt.suptitle('Borough Statistics')\n\n# Defining plot configurations\nplot_configs = [\n    ('Injuries by Borough', 'injuries', (0, 0), False),\n    ('Fatalities by Borough', 'fatalities', (0, 1), False),\n    ('Motorist Injury Rate', 'motorist_injury_rate', (1, 0), True),\n    ('Motorist Fatality Rate', 'motorist_fat_rate', (1, 1), True),\n    ('Non driver Injury Rate by Borough', 'non_driver_inj_rate', (2, 0), True),\n    ('Non driver Fat Rate by Borough', 'non_driver_fat_rate', (2, 1), True)\n]\n\ncolor_dict = {\n    'BROOKLYN': '#1f77b4',\n    'QUEENS': '#ff7f0e', \n    'MANHATTAN': '#2ca02c',\n    'BRONX': '#d62728',\n    'STATEN ISLAND': '#9467bd'\n}\n\n# Create barplots using a for loop\nfor title, column, position, is_percentage in plot_configs:\n    row, col = position\n    \n    # Setting title\n    ax[row, col].set_title(title)\n    \n    # Formatting y-axis for percentage plots\n    if is_percentage:\n        ax[row, col].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.1f}%'.format(y)))\n    \n    # Ordering plot bars\n    order = borough_stats.sort_values(column, ascending=False)['borough'].tolist()\n    \n    # Creating barplots\n    sns.barplot(data=borough_stats, x='borough', y=column, ax=ax[row, col], \n                order=order, palette=color_dict)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# NYC Now\n\nWhile not included in the scope of the analysis in 2025 YTD accidents and traffic related deaths in NYC have dropped to their lowest levels in recorded history. This shows that initiatives like Vision Zero's Implementations such as 24/7 speed cameras, corridor redesigns, street conversions, and bike lane expansions have helped to make NYC Streets not only safer, but more accessible. Its up to all of us to not only make the streets of NYC safer, but all out streets by being more mindful and attentive before we step behind the wheel.","metadata":{}},{"cell_type":"markdown","source":"# References\n\nDatasets\n- External [NYC Planning -Borough Boundaries](https://www.nyc.gov/content/planning/pages/resources/datasets/borough-boundaries)\n- External [NYC Open Data - Motor Vehicle Collisions](https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95/about_data)\n- External [NYC Open Data - Automated Traffic Volume Counts](https://data.cityofnewyork.us/Transportation/Automated-Traffic-Volume-Counts/7ym2-wayt/about_data)\n\nArticles\n\n- [NYC DOT - Vision Zero: NYC DOT Announces Traffic Deaths Reached Lowest Level in Recorded History](https://www.nyc.gov/html/dot/html/pr2025/vision-zero.shtml) \n\n\n- [NYC DOT - Year of Record Achievements, Initiatives to Reimagine the Use of Public Space](https://www.nyc.gov/html/dot/html/pr2023/nyc-dot-2023.shtml) ","metadata":{}}]}